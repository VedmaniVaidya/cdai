{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ols\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# pizza = pd.read_csv(\"pizza.csv\")\n",
    "\n",
    "# X = pizza[['Promote']]\n",
    "# y = pizza['Sales']\n",
    "X, y = make_regression(n_samples=1000, n_features=20, noise=0.1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "model = sm.OLS(y,X)\n",
    "results = model.fit()\n",
    "print(results.params)\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple linear regression\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the dataset\n",
    "# boston = pd.read_csv(\"Boston.csv\")\n",
    "\n",
    "X, y = make_regression(n_samples=1000, n_features=20, noise=0.1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the features and the target\n",
    "# X = boston.drop('medv', axis=1)\n",
    "# y = boston['medv']\n",
    "X, y = make_regression(n_samples=1000, n_features=20, noise=0.1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the Linear Regression model\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# Print the Mean Squared Error of the model on the testing set\n",
    "print(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression line plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regression line plot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Choose the first feature as an example\n",
    "feature = X.columns[0]\n",
    "\n",
    "# Scatter plot of training data\n",
    "plt.scatter(X_train[feature], y_train, color='blue', label='Train data')\n",
    "\n",
    "# Scatter plot of testing data\n",
    "plt.scatter(X_test[feature], y_test, color='red', label='Test data')\n",
    "\n",
    "# Create a range of values for the chosen feature\n",
    "x = np.linspace(min(X[feature]), max(X[feature])).reshape(-1, 1)\n",
    "\n",
    "# Predict y values for the range of x values\n",
    "y = lr.predict(pd.DataFrame(x, columns=[feature]))\n",
    "\n",
    "# Plot the regression line\n",
    "plt.plot(x, y, color='green', linewidth=3)\n",
    "\n",
    "plt.xlabel(feature)\n",
    "plt.ylabel('medv')\n",
    "plt.title('Regression Line')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L1 and L2 are different types of regularization techniques that can help to prevent overfitting in a machine learning model by adding a penalty term to the loss function.\n",
    "\n",
    "- L1 regularization, also known as Lasso regularization, adds a penalty equal to the absolute value of the magnitude of coefficients. This can result in sparse outputs where some of the coefficients can become zero, effectively excluding the corresponding feature from the model.\n",
    "\n",
    "- L2 regularization, also known as Ridge regularization, adds a penalty equal to the square of the magnitude of coefficients. This tends to spread coefficient values out more evenly.\n",
    "\n",
    "In terms of specific models:\n",
    "\n",
    "- The `Lasso` regression model uses L1 regularization.\n",
    "- The `Ridge` regression model uses L2 regularization.\n",
    "- The `ElasticNet` regression model uses a combination of both L1 and L2 regularization. The balance between them can be controlled with the `l1_ratio` parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ridge regression\n",
    "# Import necessary libraries\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X, y = make_regression(n_samples=1000, n_features=20, noise=0.1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Ridge Regression model\n",
    "ridge = Ridge(alpha=1.0)\n",
    "\n",
    "# Train the model\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred_ridge = ridge.predict(X_test)\n",
    "\n",
    "# Print the Mean Squared Error of the model on the testing set\n",
    "print(mean_squared_error(y_test, y_pred_ridge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('ridge', Ridge())\n",
    "])\n",
    "\n",
    "# Load the Boston dataset\n",
    "# boston = load_boston()\n",
    "# X, y = boston.data, boston.target\n",
    "X, y = make_regression(n_samples=1000, n_features=20, noise=0.1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "param_grid = {'ridge__alpha': np.logspace(-4, 0, 50)}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid = GridSearchCV(pipe, param_grid, cv=kfold,scoring='neg_mean_squared_error', verbose=3)\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters: \", grid.best_params_)\n",
    "print(\"Best score: \", grid.best_score_)\n",
    "model = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lasso regression\n",
    "# Import necessary libraries\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X, y = make_regression(n_samples=1000, n_features=20, noise=0.1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Lasso Regression model\n",
    "lasso = Lasso(alpha=1.0)\n",
    "\n",
    "# Train the model\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred_lasso = lasso.predict(X_test)\n",
    "\n",
    "# Print the Mean Squared Error of the model on the testing set\n",
    "print(mean_squared_error(y_test, y_pred_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# Create a synthetic regression dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=20, noise=0.1)\n",
    "\n",
    "# Split your data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Standardize data\n",
    "    ('lasso', Lasso())  # Apply Lasso regression\n",
    "])\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "param_grid = {'lasso__alpha': np.logspace(-4, 0, 50)}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid = GridSearchCV(pipe, param_grid, cv=kfold, scoring='neg_mean_squared_error', verbose=3)\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters: \", grid.best_params_)\n",
    "print(\"Best score: \", grid.best_score_)\n",
    "model = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elasticnet\n",
    "# Import necessary libraries\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X, y = make_regression(n_samples=1000, n_features=20, noise=0.1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Initialize the ElasticNet Regression model\n",
    "elasticnet = ElasticNet(alpha=1.0, l1_ratio=0.5)\n",
    "\n",
    "# Train the model\n",
    "elasticnet.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred_elasticnet = elasticnet.predict(X_test)\n",
    "\n",
    "# Print the Mean Squared Error of the model on the testing set\n",
    "print(mean_squared_error(y_test, y_pred_elasticnet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid search for elasticnet\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# Create a synthetic regression dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=20, noise=0.1)\n",
    "\n",
    "# Split your data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Standardize data\n",
    "    ('elasticnet', ElasticNet())  # Apply ElasticNet regression\n",
    "])\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "param_grid = {'elasticnet__alpha': np.logspace(-4, 0, 50),\n",
    "              'elasticnet__l1_ratio': np.linspace(0, 1, 50)}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid = GridSearchCV(pipe, param_grid, cv=kfold, scoring='neg_mean_squared_error', verbose=3)\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters: \", grid.best_params_)\n",
    "print(\"Best score: \", grid.best_score_)\n",
    "model = grid.best_estimator_\n",
    "joblib.dump(model, 'elasticnet.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# boston = pd.read_csv(\"Boston.csv\")\n",
    "# X = boston.drop('medv', axis=1)\n",
    "# y = boston['medv']\n",
    "\n",
    "X, y = make_regression(n_samples=1000, n_features=20, noise=0.1)\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the pipeline\n",
    "pipe = Pipeline([\n",
    "    ('poly', PolynomialFeatures()),  # Generate polynomial features\n",
    "    ('scaler', StandardScaler()),  # Standardize data\n",
    "    ('lr', LinearRegression())  # Apply Linear Regression\n",
    "])\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "param_grid = {'poly__degree': [1, 2, 3]}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid = GridSearchCV(pipe, param_grid, cv=kfold, scoring='neg_mean_squared_error', verbose=3)\n",
    "\n",
    "# Split your data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters: \", grid.best_params_)\n",
    "print(\"Best score: \", grid.best_score_)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "# Print the mean squared error\n",
    "print(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(grid.best_estimator_, 'linear_regression.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import make_regression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# boston = pd.read_csv(\"Boston.csv\")\n",
    "# X = boston.drop('medv', axis=1)\n",
    "# y = boston['medv']\n",
    "\n",
    "X, y = make_regression(n_samples=1000, n_features=20, noise=0.1)\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the pipeline\n",
    "pipe = Pipeline([\n",
    "    ('scaler', 'passthrough'),  # Placeholder for the scaler\n",
    "    ('regressor', 'passthrough')  # Placeholder for the regressor\n",
    "])\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "param_grid = [\n",
    "    {\n",
    "        'scaler': [StandardScaler(), MinMaxScaler()],\n",
    "        'regressor': [LinearRegression()],\n",
    "    },\n",
    "    {\n",
    "        'scaler': [StandardScaler(), MinMaxScaler()],\n",
    "        'regressor': [Ridge()],\n",
    "        'regressor__alpha': np.logspace(-4, 0, 50)\n",
    "    },\n",
    "    {\n",
    "        'scaler': [StandardScaler(), MinMaxScaler()],\n",
    "        'regressor': [Lasso()],\n",
    "        'regressor__alpha': np.logspace(-4, 0, 50)\n",
    "    },\n",
    "    {\n",
    "        'scaler': [StandardScaler(), MinMaxScaler()],\n",
    "        'regressor': [ElasticNet()],\n",
    "        'regressor__alpha': np.logspace(-4, 0, 50),\n",
    "        'regressor__l1_ratio': [0.1, 0.5, 0.9]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid = GridSearchCV(pipe, param_grid, cv=kfold, scoring='neg_mean_squared_error', verbose=3)\n",
    "\n",
    "# Split your data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters: \", grid.best_params_)\n",
    "print(\"Best score: \", grid.best_score_)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "# Print the mean squared error\n",
    "print(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(grid.best_estimator_, 'best_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=2, n_redundant=10, n_classes=2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the pipeline\n",
    "pipe = Pipeline([\n",
    "    ('scaler', 'passthrough'),  # Placeholder for the scaler\n",
    "    ('classifier', 'passthrough')  # Placeholder for the classifier\n",
    "])\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "param_grid = [\n",
    "    {\n",
    "        'scaler': [StandardScaler(), MinMaxScaler()],\n",
    "        'classifier': [LogisticRegression()],\n",
    "        'classifier__penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "        'classifier__solver': ['lbfgs', 'liblinear', 'newton-cg', 'sag', 'saga']\n",
    "    }\n",
    "]\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid = GridSearchCV(pipe, param_grid, cv=kfold, scoring='accuracy')\n",
    "\n",
    "# Fit the model to the data\n",
    "grid.fit(X, y)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters: \", grid.best_params_)\n",
    "print(\"Best score: \", grid.best_score_)\n",
    "\n",
    "# Perform grid search with cross-validation for log loss\n",
    "grid = GridSearchCV(pipe, param_grid, cv=kfold, scoring='neg_log_loss')\n",
    "\n",
    "# Fit the model to the data\n",
    "grid.fit(X, y)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters: \", grid.best_params_)\n",
    "print(\"Best score: \", grid.best_score_)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(grid.best_estimator_, 'best_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=2, n_redundant=10, n_classes=2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the pipeline\n",
    "pipe = Pipeline([\n",
    "    ('scaler', 'passthrough'),  # Placeholder for the scaler\n",
    "    ('classifier', 'passthrough')  # Placeholder for the classifier\n",
    "])\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "param_grid = [\n",
    "    {\n",
    "        'scaler': [StandardScaler(), MinMaxScaler()],\n",
    "        'classifier': [LogisticRegression()],\n",
    "        'classifier__penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "        'classifier__solver': ['lbfgs', 'liblinear', 'newton-cg', 'sag', 'saga']\n",
    "    }\n",
    "]\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid = GridSearchCV(pipe, param_grid, cv=kfold, scoring='accuracy')\n",
    "\n",
    "# Fit the model to the data\n",
    "grid.fit(X, y)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters: \", grid.best_params_)\n",
    "print(\"Best score: \", grid.best_score_)\n",
    "\n",
    "# Perform grid search with cross-validation for log loss\n",
    "grid = GridSearchCV(pipe, param_grid, cv=kfold, scoring='neg_log_loss')\n",
    "\n",
    "# Fit the model to the data\n",
    "grid.fit(X, y)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters: \", grid.best_params_)\n",
    "print(\"Best score: \", grid.best_score_)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(grid.best_estimator_, 'best_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Generate synthetic data\n",
    "\n",
    "# Generate synthetic data\n",
    "X, y = make_blobs(n_samples=1000, n_features=20, centers=5, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define cross-validation strategy\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the pipeline\n",
    "pipe = Pipeline([\n",
    "    ('scaler', 'passthrough'),  # Placeholder for the scaler\n",
    "    ('classifier', 'passthrough')  # Placeholder for the classifier\n",
    "])\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "param_grid = [\n",
    "    {\n",
    "        'scaler': [StandardScaler(), MinMaxScaler()],\n",
    "        'classifier': [LogisticRegression()],\n",
    "        'classifier__penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "        'classifier__solver': ['lbfgs', 'liblinear', 'newton-cg', 'sag', 'saga'],\n",
    "        'classifier__multi_class': ['ovr', 'multinomial']\n",
    "    }\n",
    "]\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid = GridSearchCV(pipe, param_grid, cv=kfold, scoring='accuracy')\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters: \", grid.best_params_)\n",
    "print(\"Best score: \", grid.best_score_)\n",
    "model = grid.best_estimator_\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(grid.best_estimator_, 'best_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Predict the test set results\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=2, n_redundant=10, n_classes=2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the pipeline\n",
    "pipe = Pipeline([\n",
    "    ('scaler', 'passthrough'),  # Placeholder for the scaler\n",
    "    ('classifier', 'passthrough')  # Placeholder for the classifier\n",
    "])\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "param_grid = [\n",
    "    {\n",
    "        'scaler': [StandardScaler(), MinMaxScaler()],\n",
    "        'classifier': [KNeighborsClassifier()],\n",
    "        'classifier__n_neighbors': np.arange(1, 11)\n",
    "    }\n",
    "]\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid = GridSearchCV(pipe, param_grid, cv=kfold, scoring='accuracy')\n",
    "\n",
    "# Fit the model to the data\n",
    "grid.fit(X, y)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters: \", grid.best_params_)\n",
    "print(\"Best score: \", grid.best_score_)\n",
    "\n",
    "# Perform grid search with cross-validation for log loss\n",
    "grid = GridSearchCV(pipe, param_grid, cv=kfold, scoring='neg_log_loss')\n",
    "\n",
    "# Fit the model to the data\n",
    "grid.fit(X, y)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters: \", grid.best_params_)\n",
    "print(\"Best score: \", grid.best_score_)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(grid.best_estimator_, 'best_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "# Load the California housing dataset\n",
    "california = fetch_california_housing()\n",
    "X, y = california.data, california.target\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the pipeline\n",
    "pipe = Pipeline([\n",
    "    ('scaler', 'passthrough'),  # Placeholder for the scaler\n",
    "    ('regressor', 'passthrough')  # Placeholder for the regressor\n",
    "])\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "param_grid = [\n",
    "    {\n",
    "        'scaler': [StandardScaler(), MinMaxScaler()],\n",
    "        'regressor': [KNeighborsRegressor()],\n",
    "        'regressor__n_neighbors': np.arange(1, 11)\n",
    "    }\n",
    "]\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid = GridSearchCV(pipe, param_grid, cv=kfold, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters: \", grid.best_params_)\n",
    "print(\"Best score: \", grid.best_score_)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(grid.best_estimator_, 'best_model.pkl')\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "# Compute the mean squared error of the prediction\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Print the mean squared error\n",
    "print(\"Test set MSE: \", mse)\n",
    "\n",
    "# Compute the R2 score of the prediction\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print the R2 score\n",
    "print(\"Test set R2 score: \", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "# Load the digits dataset\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the pipeline\n",
    "pipe = Pipeline([\n",
    "    ('scaler', 'passthrough'),  # Placeholder for the scaler\n",
    "    ('classifier', 'passthrough')  # Placeholder for the classifier\n",
    "])\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "param_grid = [\n",
    "    {\n",
    "        'scaler': [StandardScaler(), MinMaxScaler()],\n",
    "        'classifier': [BernoulliNB()],\n",
    "        'classifier__alpha': np.linspace(0.1, 1, 10)\n",
    "    }\n",
    "]\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid = GridSearchCV(pipe, param_grid, cv=kfold, scoring='accuracy')\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters: \", grid.best_params_)\n",
    "print(\"Best score: \", grid.best_score_)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(grid.best_estimator_, 'best_model.pkl')\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "# Compute the accuracy of the prediction\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Test set accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "# Load the breast cancer dataset\n",
    "cancer = load_breast_cancer()\n",
    "X, y = cancer.data, cancer.target\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the pipeline\n",
    "pipe = Pipeline([\n",
    "    ('scaler', 'passthrough'),  # Placeholder for the scaler\n",
    "    ('classifier', 'passthrough')  # Placeholder for the classifier\n",
    "])\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "param_grid = [\n",
    "    {\n",
    "        'scaler': [StandardScaler(), MinMaxScaler()],\n",
    "        'classifier': [LinearDiscriminantAnalysis()],\n",
    "        'classifier__solver': ['svd', 'lsqr', 'eigen']\n",
    "    }\n",
    "]\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid = GridSearchCV(pipe, param_grid, cv=kfold, scoring='accuracy')\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters: \", grid.best_params_)\n",
    "print(\"Best score: \", grid.best_score_)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(grid.best_estimator_, 'best_model.pkl')\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "# Compute the accuracy of the prediction\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Test set accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Load the breast cancer dataset\n",
    "cancer = load_breast_cancer()\n",
    "X, y = cancer.data, cancer.target\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the pipeline\n",
    "pipe = Pipeline([\n",
    "    ('scaler', 'passthrough'),  # Placeholder for the scaler\n",
    "    ('classifier', 'passthrough')  # Placeholder for the classifier\n",
    "])\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "param_grid = [\n",
    "    {\n",
    "        'scaler': [StandardScaler(), MinMaxScaler()],\n",
    "        'classifier': [SVC(kernel='linear')],\n",
    "        'classifier__C': np.logspace(-3, 3, 7)\n",
    "    }\n",
    "]\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid = GridSearchCV(pipe, param_grid, cv=kfold, scoring='neg_log_loss')\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters: \", grid.best_params_)\n",
    "print(\"Best score: \", grid.best_score_)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(grid.best_estimator_, 'best_model.pkl')\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "# Compute the accuracy of the prediction\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Test set accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Load the boston dataset\n",
    "california = fetch_california_housing()\n",
    "X, y = california.data, california.target\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the pipeline\n",
    "pipe = Pipeline([\n",
    "    ('scaler', 'passthrough'),  # Placeholder for the scaler\n",
    "    ('regressor', 'passthrough')  # Placeholder for the regressor\n",
    "])\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "param_grid = [\n",
    "    {\n",
    "        'scaler': [StandardScaler(), MinMaxScaler()],\n",
    "        'regressor': [SVR(kernel='linear')],\n",
    "        'regressor__C': np.logspace(-3, 3, 7)\n",
    "    }\n",
    "]\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid = GridSearchCV(pipe, param_grid, cv=kfold, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters: \", grid.best_params_)\n",
    "print(\"Best score: \", grid.best_score_)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(grid.best_estimator_, 'best_model.pkl')\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "# Compute the mean squared error of the prediction\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Print the mean squared error\n",
    "print(\"Test set MSE: \", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Load the breast cancer dataset\n",
    "cancer = load_breast_cancer()\n",
    "X, y = cancer.data, cancer.target\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the pipeline\n",
    "pipe = Pipeline([\n",
    "    ('scaler', 'passthrough'),  # Placeholder for the scaler\n",
    "    ('classifier', 'passthrough')  # Placeholder for the classifier\n",
    "])\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "param_grid = [\n",
    "    {\n",
    "        'scaler': [StandardScaler(), MinMaxScaler()],\n",
    "        'classifier': [SVC(kernel='rbf')],\n",
    "        'classifier__C': np.logspace(-3, 3, 7),\n",
    "        'classifier__gamma': np.logspace(-3, 3, 7)\n",
    "    }\n",
    "]\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid = GridSearchCV(pipe, param_grid, cv=kfold, scoring='neg_log_loss')\n",
    "# random_search = RandomizedSearchCV(pipe, param_grid, n_iter=50, cv=kfold, scoring='neg_log_loss', random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters: \", grid.best_params_)\n",
    "print(\"Best score: \", grid.best_score_)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(grid.best_estimator_, 'best_model.pkl')\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "# Compute the accuracy of the prediction\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Test set accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "california = fetch_california_housing()\n",
    "X, y = california.data, california.target\n",
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the pipeline\n",
    "pipe = Pipeline([\n",
    "    ('scaler', 'passthrough'),  # Placeholder for the scaler\n",
    "    ('regressor', 'passthrough')  # Placeholder for the regressor\n",
    "])\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "param_grid = {\n",
    "    'scaler': [StandardScaler(), MinMaxScaler()],\n",
    "    'regressor': [SVR(kernel='rbf')],\n",
    "    'regressor__C': np.logspace(-3, 3, 7),\n",
    "    'regressor__gamma': np.logspace(-3, 3, 7)\n",
    "}\n",
    "\n",
    "# Perform random search with cross-validation\n",
    "random_search = RandomizedSearchCV(pipe, param_grid, n_iter=50, cv=kfold, scoring='neg_mean_squared_error', random_state=42, verbose=3)\n",
    "\n",
    "# Fit the model to the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters: \", random_search.best_params_)\n",
    "print(\"Best score: \", random_search.best_score_)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(random_search.best_estimator_, 'best_model.pkl')\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_pred = random_search.predict(X_test)\n",
    "\n",
    "# Compute the mean squared error of the prediction\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Print the mean squared error\n",
    "print(\"Test set MSE: \", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Load the breast cancer dataset\n",
    "cancer = load_breast_cancer()\n",
    "X, y = cancer.data, cancer.target\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the pipeline\n",
    "pipe = Pipeline([\n",
    "    ('scaler', 'passthrough'),  # Placeholder for the scaler\n",
    "    ('classifier', 'passthrough')  # Placeholder for the classifier\n",
    "])\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "param_grid = {\n",
    "    'scaler': [StandardScaler(), MinMaxScaler()],\n",
    "    'classifier': [DecisionTreeClassifier()],\n",
    "    'classifier__max_depth': np.arange(1, 10),\n",
    "    'classifier__min_samples_split': np.arange(2, 10),\n",
    "    'classifier__min_samples_leaf': np.arange(1, 10)\n",
    "}\n",
    "\n",
    "# Perform random search with cross-validation\n",
    "random_search = RandomizedSearchCV(pipe, param_grid, n_iter=50, cv=kfold, scoring='neg_log_loss', random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters: \", random_search.best_params_)\n",
    "print(\"Best score: \", random_search.best_score_)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(random_search.best_estimator_, 'best_model.pkl')\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_pred = random_search.predict(X_test)\n",
    "\n",
    "# Compute the accuracy of the prediction\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Test set accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Load the california housing dataset\n",
    "california = fetch_california_housing()\n",
    "X, y = california.data, california.target\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the pipeline\n",
    "pipe = Pipeline([\n",
    "    ('scaler', 'passthrough'),  # Placeholder for the scaler\n",
    "    ('regressor', 'passthrough')  # Placeholder for the regressor\n",
    "])\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "param_grid = {\n",
    "    'scaler': [StandardScaler(), MinMaxScaler()],\n",
    "    'regressor': [DecisionTreeRegressor()],\n",
    "    'regressor__max_depth': np.arange(1, 10),\n",
    "    'regressor__min_samples_split': np.arange(2, 10),\n",
    "    'regressor__min_samples_leaf': np.arange(1, 10)\n",
    "}\n",
    "\n",
    "# Perform random search with cross-validation\n",
    "random_search = RandomizedSearchCV(pipe, param_grid, n_iter=50, cv=kfold, scoring='neg_mean_squared_error', random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters: \", random_search.best_params_)\n",
    "print(\"Best score: \", random_search.best_score_)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(random_search.best_estimator_, 'best_model.pkl')\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_pred = random_search.predict(X_test)\n",
    "\n",
    "# Compute the mean squared error of the prediction\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Print the mean squared error\n",
    "print(\"Test set MSE: \", mse)\n",
    "\n",
    "# print r2_score\n",
    "from sklearn.metrics import r2_score\n",
    "print(\"R2 Score: \", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn impute missing values simple imputer and KNN imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Intentionally add some missing values\n",
    "np.random.seed(42)\n",
    "X[np.random.randint(X.shape[0], size=20), np.random.randint(X.shape[1], size=20)] = np.nan\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# SimpleImputer\n",
    "simple_imputer = SimpleImputer(strategy='mean')\n",
    "X_train_simple_imputed = simple_imputer.fit_transform(X_train)\n",
    "X_test_simple_imputed = simple_imputer.transform(X_test)\n",
    "\n",
    "# KNNImputer\n",
    "knn_imputer = KNNImputer(n_neighbors=3)\n",
    "X_train_knn_imputed = knn_imputer.fit_transform(X_train)\n",
    "X_test_knn_imputed = knn_imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the california housing dataset\n",
    "california = fetch_california_housing()\n",
    "X, y = california.data, california.target\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create a pipeline with a StandardScaler and a BaggingRegressor\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('bagging', BaggingRegressor(random_state=23))\n",
    "])\n",
    "\n",
    "# Define the parameter grid for RandomizedSearchCV\n",
    "param_grid = {\n",
    "    'bagging__n_estimators': [10, 50, 100, 200],\n",
    "    'bagging__max_samples': [0.5, 1.0],\n",
    "    'bagging__max_features': [0.5, 1.0],\n",
    "    # 'bagging__bootstrap': [True, False],\n",
    "    # 'bagging__bootstrap_features': [True, False]\n",
    "}\n",
    "\n",
    "# Perform RandomizedSearchCV with the pipeline\n",
    "rgcv = RandomizedSearchCV(pipeline, param_distributions=param_grid, cv=5, scoring='neg_mean_squared_error', random_state=42, n_iter=50, verbose=3)\n",
    "rgcv.fit(X_train, y_train)\n",
    "\n",
    "# Print the best score and best parameters\n",
    "print(\"Best score: \", -rgcv.best_score_)  # Multiply by -1 because the score is the negative MSE\n",
    "print(\"Best parameters: \", rgcv.best_params_)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_pred = rgcv.predict(X_test)\n",
    "\n",
    "# Compute the mean squared error and R2 score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print the MSE and R2 score\n",
    "print(\"Mean Squared Error: \", mse)\n",
    "print(\"R2 Score: \", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define the model object\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Create a pipeline with a StandardScaler and a BaggingClassifier\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('bagging', BaggingClassifier(base_estimator=knn, random_state=23))\n",
    "])\n",
    "\n",
    "# Define the parameter grid for RandomizedSearchCV\n",
    "param_grid = {\n",
    "    'bagging__n_estimators': [10, 50, 100, 200],\n",
    "    'bagging__max_samples': [0.5, 1.0],\n",
    "    'bagging__max_features': [0.5, 1.0],\n",
    "    'bagging__base_estimator__n_neighbors': np.arange(1, 20, 1),  # parameters for KNeighborsClassifier\n",
    "}\n",
    "\n",
    "# Perform RandomizedSearchCV with the pipeline\n",
    "rgcv = RandomizedSearchCV(pipeline, param_distributions=param_grid, cv=5, scoring='neg_log_loss', random_state=42, n_iter=50, verbose=3)\n",
    "rgcv.fit(X_train, y_train)\n",
    "\n",
    "# Print the best score and best parameters\n",
    "print(\"Best score: \", -rgcv.best_score_)  # Multiply by -1 because the score is the negative log loss\n",
    "print(\"Best parameters: \", rgcv.best_params_)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_pred = rgcv.predict(X_test)\n",
    "\n",
    "# Compute the confusion matrix and F1 score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Print the confusion matrix and F1 score\n",
    "print(\"Confusion Matrix: \\n\", cm)\n",
    "print(\"F1 Score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=23)\n",
    "\n",
    "# Create a pipeline with a StandardScaler and a RandomForestClassifier\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', RandomForestClassifier(random_state=23))\n",
    "])\n",
    "\n",
    "# Define the parameter grid for RandomizedSearchCV\n",
    "param_grid = {\n",
    "    'rf__n_estimators': [10, 50, 100, 200],\n",
    "    'rf__max_depth': [None, 5, 10, 15, 20],\n",
    "    'rf__min_samples_split': [2, 5, 10],\n",
    "    'rf__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Perform RandomizedSearchCV with the pipeline\n",
    "rgcv = RandomizedSearchCV(pipeline, param_distributions=param_grid, cv=5, scoring='neg_log_loss', random_state=23, n_iter=50, verbose=3)\n",
    "rgcv.fit(X_train, y_train)\n",
    "\n",
    "# Print the best score and best parameters\n",
    "print(\"Best score: \", -rgcv.best_score_)  # Multiply by -1 because the score is the negative log loss\n",
    "print(\"Best parameters: \", rgcv.best_params_)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_pred = rgcv.predict(X_test)\n",
    "\n",
    "# Compute the confusion matrix and F1 score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Print the confusion matrix and F1 score\n",
    "print(\"Confusion Matrix: \\n\", cm)\n",
    "print(\"F1 Score: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Load the boston dataset\n",
    "housing = fetch_california_housing()\n",
    "X, y = housing.data, housing.target\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create a pipeline with a StandardScaler and a RandomForestRegressor\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', RandomForestRegressor(random_state=23))\n",
    "])\n",
    "\n",
    "# Define the parameter grid for RandomizedSearchCV\n",
    "param_grid = {\n",
    "    'rf__n_estimators': [10, 50, 100, 200],\n",
    "    'rf__max_depth': [None, 5, 10, 15, 20],\n",
    "    'rf__min_samples_split': [2, 5, 10],\n",
    "    'rf__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Perform RandomizedSearchCV with the pipeline\n",
    "rgcv = RandomizedSearchCV(pipeline, param_distributions=param_grid, cv=5, scoring='neg_mean_squared_error', random_state=42, n_iter=50, verbose=3)\n",
    "rgcv.fit(X_train, y_train)\n",
    "\n",
    "# Print the best score and best parameters\n",
    "print(\"Best score: \", np.sqrt(-rgcv.best_score_))  # Multiply by -1 and take the square root because the score is the negative mean squared error\n",
    "print(\"Best parameters: \", rgcv.best_params_)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_pred = rgcv.predict(X_test)\n",
    "\n",
    "# Compute the mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Print the mean squared error\n",
    "print(\"Mean Squared Error: \", mse)\n",
    "\n",
    "# print r2_score\n",
    "from sklearn.metrics import r2_score\n",
    "print(\"R2 Score: \", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingRegressor, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Load the wine dataset\n",
    "wine = load_wine()\n",
    "X, y = wine.data, wine.target\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=23)\n",
    "\n",
    "# Define the individual regressors\n",
    "rfr = RandomForestRegressor(random_state=23)\n",
    "lr = LinearRegression()\n",
    "dtr = DecisionTreeRegressor(random_state=23)\n",
    "\n",
    "# Combine the regressors in the ensemble model\n",
    "voting = VotingRegressor(estimators=[('RFR', rfr), ('LR', lr), ('DTR', dtr)])\n",
    "\n",
    "# Define the parameter grid for RandomizedSearchCV\n",
    "param_grid = {'RFR__n_estimators': [50, 100, 200],\n",
    "              'RFR__max_depth': [2,4,6,8,10,None],\n",
    "              'DTR__max_depth': [2,4,6,8,10,None],\n",
    "              'DTR__min_samples_split':[2,5,10,15,20],\n",
    "              'DTR__min_samples_leaf':[1,5,10,15,20]}\n",
    "\n",
    "# Perform RandomizedSearchCV with the VotingRegressor\n",
    "rgcv = RandomizedSearchCV(voting, param_distributions=param_grid, verbose=3, cv=5, scoring='neg_mean_squared_error', random_state=23, n_iter=50)\n",
    "rgcv.fit(X_train, y_train)\n",
    "\n",
    "# Print the best score and best parameters\n",
    "print(\"Best score: \", -rgcv.best_score_)  # Multiply by -1 because the score is the negative MSE\n",
    "print(\"Best parameters: \", rgcv.best_params_)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_pred = rgcv.predict(X_test)\n",
    "\n",
    "# Compute the mean squared error of the prediction\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Print the MSE\n",
    "print(\"Test set MSE: \", mse)\n",
    "\n",
    "# print r2_score\n",
    "from sklearn.metrics import r2_score\n",
    "print(\"R2 Score: \", r2_score(y_test, y_pred))\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(rgcv, 'model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV, train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=23)\n",
    "\n",
    "# Define the individual classifiers\n",
    "svm = SVC(probability=True, random_state=23)\n",
    "lr = LogisticRegression(random_state=23)\n",
    "dtc = DecisionTreeClassifier(random_state=23)\n",
    "\n",
    "# Combine the classifiers in the ensemble model\n",
    "voting = VotingClassifier(estimators=[('SVM',svm), ('LR',lr), ('TREE',dtc)], voting='soft')\n",
    "\n",
    "# Define the cross-validation strategy\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=23)\n",
    "\n",
    "# Define the parameter grid for RandomizedSearchCV\n",
    "param_grid = {'SVM__gamma':['scale','auto'],\n",
    "          'SVM__C': np.linspace(0.001,10, 10),\n",
    "          'SVM__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "          'LR__penalty':['l1','l2', 'elasticnet', None],\n",
    "          'LR__C': np.logspace(-4, 4, 20),\n",
    "          'LR__multi_class':['ovr','multinomial'],\n",
    "          'TREE__max_depth': [2,4,6,8,10,None],\n",
    "          'TREE__min_samples_split':[2,5,10,15,20],\n",
    "          'TREE__min_samples_leaf':[1,5,10,15,20]}\n",
    "\n",
    "# Perform RandomizedSearchCV with the VotingClassifier\n",
    "rgcv = RandomizedSearchCV(voting, param_distributions=param_grid, verbose=3, cv=kfold, scoring='neg_log_loss', random_state=23, n_iter=10)\n",
    "rgcv.fit(X_train, y_train)\n",
    "\n",
    "# Print the best score and best parameters\n",
    "print(\"Best score: \", rgcv.best_score_)\n",
    "print(\"Best parameters: \", rgcv.best_params_)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_pred = rgcv.predict(X_test)\n",
    "\n",
    "# Compute the accuracy of the prediction\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Test set accuracy: \", accuracy)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(rgcv, 'model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_feature_importance(model, feature_names):\n",
    "    # Get feature importances\n",
    "    importances = model.feature_importances_\n",
    "\n",
    "    # Sort the feature importances in descending order and get the indices\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    # Rearrange feature names so they match the sorted feature importances\n",
    "    names = [feature_names[i] for i in indices]\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Create a bar chart, in order of importance\n",
    "    plt.bar(range(len(importances)), importances[indices])\n",
    "\n",
    "    # Add feature names as x-axis labels\n",
    "    plt.xticks(range(len(importances)), names, rotation=90)\n",
    "\n",
    "    # Set chart title and labels\n",
    "    plt.title(\"Feature Importance\")\n",
    "    plt.xlabel(\"Feature\")\n",
    "    plt.ylabel(\"Importance\")\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with the model and feature names\n",
    "plot_feature_importance(rgcv.best_estimator_.named_steps['xgb'], california.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gradient boosting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create a pipeline with a StandardScaler and a GradientBoostingClassifier\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('gbc', GradientBoostingClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Define the parameter grid for RandomizedSearchCV\n",
    "param_grid = {\n",
    "    'gbc__max_depth': [2, 3, 4, 5, 6, None],\n",
    "    'gbc__learning_rate': np.linspace(0.001, 0.999, 10),\n",
    "    'gbc__n_estimators': [50, 100, 150]\n",
    "}\n",
    "\n",
    "# param_grid = {\n",
    "#     'gbc__max_depth': [3, 5, 7, 9, None],\n",
    "#     'gbc__min_samples_split': [2, 5, 10],\n",
    "#     'gbc__min_samples_leaf': [1, 2, 4],\n",
    "#     'gbc__learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "#     'gbc__n_estimators': [50, 100, 150, 200],\n",
    "#     'gbc__subsample': [0.5, 0.7, 1.0],\n",
    "#     'gbc__max_features': ['auto', 'sqrt', 'log2', None]\n",
    "# }\n",
    "\n",
    "# Perform RandomizedSearchCV with the pipeline\n",
    "rgcv = RandomizedSearchCV(pipeline, param_distributions=param_grid, cv=5, scoring='neg_log_loss', random_state=42, n_iter=50, verbose=3)\n",
    "rgcv.fit(X_train, y_train)\n",
    "\n",
    "# Print the best score and best parameters\n",
    "print(\"Best score: \", rgcv.best_score_)\n",
    "print(\"Best parameters: \", rgcv.best_params_)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_pred = rgcv.predict(X_test)\n",
    "\n",
    "# Compute the confusion matrix and F1 score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Print the confusion matrix and F1 score\n",
    "print(\"Confusion Matrix: \\n\", cm)\n",
    "print(\"F1 Score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gradient boosting regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Load the California housing dataset\n",
    "california = fetch_california_housing()\n",
    "X, y = california.data, california.target\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create a pipeline with a StandardScaler and a GradientBoostingRegressor\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('gbr', GradientBoostingRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Define the parameter grid for RandomizedSearchCV\n",
    "param_grid = {\n",
    "    'gbr__max_depth': [2, 3, 4, 5, 6, None],\n",
    "    'gbr__learning_rate': np.linspace(0.001, 0.999, 10),\n",
    "    'gbr__n_estimators': [50, 100, 150]\n",
    "}\n",
    "\n",
    "# Perform RandomizedSearchCV with the pipeline\n",
    "rgcv = RandomizedSearchCV(pipeline, param_distributions=param_grid, cv=5, scoring='neg_mean_squared_error', random_state=42, n_iter=50, verbose=3)\n",
    "rgcv.fit(X_train, y_train)\n",
    "\n",
    "# Print the best score and best parameters\n",
    "print(\"Best score: \", np.sqrt(-rgcv.best_score_))  # Multiply by -1 and take the square root because the score is the negative mean squared error\n",
    "print(\"Best parameters: \", rgcv.best_params_)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_pred = rgcv.predict(X_test)\n",
    "\n",
    "# Compute the mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Print the mean squared error\n",
    "print(\"Mean Squared Error: \", mse)\n",
    "\n",
    "# print r2_score\n",
    "from sklearn.metrics import r2_score\n",
    "print(\"R2 Score: \", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xtreme gradient boosting or xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgbclassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create a pipeline with a StandardScaler and a XGBClassifier\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('xgb', XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42))\n",
    "])\n",
    "\n",
    "# Define the parameter grid for RandomizedSearchCV\n",
    "param_grid = {\n",
    "    'xgb__max_depth': [2, 3, 4, 5, 6, None],\n",
    "    'xgb__learning_rate': np.linspace(0.001, 0.1, 10),\n",
    "    'xgb__n_estimators': [50, 100, 150]\n",
    "}\n",
    "\n",
    "# Perform RandomizedSearchCV with the pipeline\n",
    "rgcv = RandomizedSearchCV(pipeline, param_distributions=param_grid, cv=5, scoring='neg_log_loss', random_state=42, n_iter=50, verbose=3)\n",
    "rgcv.fit(X_train, y_train)\n",
    "\n",
    "# Print the best score and best parameters\n",
    "print(\"Best score: \", -rgcv.best_score_)  # Multiply by -1 because the score is the negative log loss\n",
    "print(\"Best parameters: \", rgcv.best_params_)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_pred = rgcv.predict(X_test)\n",
    "\n",
    "# Compute the confusion matrix and F1 score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Print the confusion matrix and F1 score\n",
    "print(\"Confusion Matrix: \\n\", cm)\n",
    "print(\"F1 Score: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Load the California housing dataset\n",
    "california = fetch_california_housing()\n",
    "X, y = california.data, california.target\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create a pipeline with a StandardScaler and a XGBRegressor\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('xgb', XGBRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Define the parameter grid for RandomizedSearchCV\n",
    "param_grid = {\n",
    "    'xgb__max_depth': [3, 5, 7, None],\n",
    "    'xgb__learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "    'xgb__n_estimators': [50, 100, 150, 200],\n",
    "    # 'xgb__subsample': [0.5, 0.7, 1.0],\n",
    "    # 'xgb__colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    # 'xgb__gamma': [0, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Perform RandomizedSearchCV with the pipeline\n",
    "rgcv = RandomizedSearchCV(pipeline, param_distributions=param_grid, cv=5, scoring='neg_mean_squared_error', random_state=42, n_iter=50, verbose=3)\n",
    "rgcv.fit(X_train, y_train)\n",
    "\n",
    "# Print the best score and best parameters\n",
    "print(\"Best score: \", np.sqrt(-rgcv.best_score_))  # Multiply by -1 and take the square root because the score is the negative mean squared error\n",
    "print(\"Best parameters: \", rgcv.best_params_)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_pred = rgcv.predict(X_test)\n",
    "\n",
    "# Compute the mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Print the mean squared error\n",
    "print(\"Mean Squared Error: \", mse)\n",
    "\n",
    "# print r2_score\n",
    "from sklearn.metrics import r2_score\n",
    "print(\"R2 Score: \", r2_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
